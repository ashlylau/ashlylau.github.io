{"componentChunkName":"component---src-components-md-template-js","path":"/projects/privacy-ml","result":{"data":{"markdownRemark":{"html":"<p><strong>Abstract</strong>:</p>\n<p>Differential privacy provides strong privacy guarantees for machine learning applications, and it is increasingly being studied in research and in practical applications. Much recent work has been focused on developing differentially private models. However, there has been a gap in other stages of the machine learning pipeline, in particular during the data preprocessing phase. To successfully integrate differential privacy into practical machine learning settings, there is a need to study differential privacy guarantees of full machine learning pipelines.</p>\n<p>Our contributions are twofold: we firstly adapt a privacy violation detection framework based on statistical methods to empirically measure privacy levels of machine learning pipelines, where previ- ous efforts have measured differential privacy of only machine learning models through adversarial methods. We then use our newly created framework to show that resampling techniques commonly used when dealing with imbalanced datasets cause the resultant model to leak more privacy. Our results highlight the crucial need for developing differentially private resampling techniques, and we use insights from our evaluation to explore promising directions in developing these algorithms.</p>","frontmatter":{"path":"/projects/privacy-ml","image":{"childImageSharp":{"fluid":{"base64":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsTAAALEwEAmpwYAAACT0lEQVQoz42TeVPTUBTF+ZwsFqjo1+BPdJRv4DKjQikgFsaRNpDuFtMtbbM1TdKkS+iSPkWdQWbwHd9rxb9QzMyZm5mc+7v3JC9zK9GGc/9tEytR5ScTVndVLEYULDAtRlRW1en9TZ3fbmCBaSky8/IepusHhzav8tzKzgy4yoDcsMwM6wkTT8UmNgR9qscnBh4JBp6IJjbTNjZTFtbj5tT7G3oLcJcDFdzbURErmqhWqkgksxDTXDmcprIoSGVUFPZMaeGw2MLSzgy4+i9gKKriuSAjkZZwePoJyUINiWwF8WwZQr6GI7EIIVPGqyQbzry85y9AdbYhMwl1B5+HfYzHI0wCpvEAFyTA1eV3BKMBfnydQHKG03cavmtDDnxfMtFp27AdB6btolQ3IKst1HQbuWIdpUodB2cGi/w/GzJTot5GMPAxDgI0dAuJTAm5koKPFQNV3UWu0sLLlI7l2XZ3R05qXYz9Dnq9Li6+TDA672E89EGvr8AvuT1B1iZs+F0fhU0L7Wp4JlQRi+ewFz9D7FTCgVDA3nEeKUmBKGkQcjW8TmvTNLdGDv85hwplJnost6nvOrQm5WlTN6jn+dSx+7TbO6em3aZdz6MnDY+yH4DyHn4O12I3wKjirr1rsUkawnsa21BHwR6hFt/HSeQF+lYLWkaEnk1hMhzB9Tz4Xhui4mIpqiO8r/PY9OGRy4H1udBWtRralr8tb8sTJrKwJROx4RIy6BJLLZOOZRG/3yFGOU882yKabhDHNMiHcpPMv5EJ72H9AdMlY2V+AbCd6xHaAsIdAAAAAElFTkSuQmCC","aspectRatio":1.6666666666666667,"src":"/static/d98b5a10222389c9649e61349097d3a4/ee604/tpdp.png","srcSet":"/static/d98b5a10222389c9649e61349097d3a4/69585/tpdp.png 200w,\n/static/d98b5a10222389c9649e61349097d3a4/497c6/tpdp.png 400w,\n/static/d98b5a10222389c9649e61349097d3a4/ee604/tpdp.png 800w,\n/static/d98b5a10222389c9649e61349097d3a4/f3583/tpdp.png 1200w,\n/static/d98b5a10222389c9649e61349097d3a4/5707d/tpdp.png 1600w,\n/static/d98b5a10222389c9649e61349097d3a4/9a46f/tpdp.png 1824w","sizes":"(max-width: 800px) 100vw, 800px"}}},"title":"TPDP 2021 Submission","desc":"Statistical Privacy Guarantees of Machine Learning Preprocessing Techniques","additional":"MEng individual project which was accepted for the poster workshop at TPDP 2021"}}},"pageContext":{}}}